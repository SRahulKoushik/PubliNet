# Overcoming Brittleness in Pareto-Optimal Learning-Augmented Algorithms

Spyros Angelopoulos Christoph Dürr

Alex Elenter Yanni Lefki Sorbonne Université, CNRS, LIP6, Paris, France Ecole Polytechnique, Palaiseau, France

Sorbonne Université, CNRS, LIP6, Paris, France Sorbonne Université, CNRS, LIP6, Paris, France

#### ABSTRACT

The study of online algorithms with machine-learned predictions has gained considerable prominence in recent years. One of the common objectives in the design and analysis of such algorithms is to attain (Pareto) optimal tradeoffs between the *consistency* of the algorithm, i.e., its performance assuming perfect predictions, and its *robustness*, i.e., the performance of the algorithm under adversarial predictions. In this work, we demonstrate that this optimization criterion can be extremely brittle, in that the performance of Pareto-optimal algorithms may degrade dramatically even in the presence of imperceptive prediction error. To remedy this drawback, we propose a new framework in which the smoothness in the performance of the algorithm is enforced by means of a *user-specified profile*. This allows us to regulate the performance of the algorithm as a function of the prediction error, while simultaneously maintaining the analytical notion of consistency/robustness tradeoffs, adapted to the profile setting. We apply this new approach to a well-studied online problem, namely the *one-way trading* problem. For this problem, we further address another limitation of the state-of-the-art Paretooptimal algorithms, namely the fact that they are tailored to worst-case, and extremely pessimistic inputs. We propose a new Pareto-optimal algorithm that leverages any deviation from the worst-case input to its benefit, and introduce a new metric that allows us to compare any two Pareto-optimal algorithms via a *dominance* relation.

### 1 Introduction

The field of learning-augmented online algorithms has witnessed remarkable growth in recent years, starting with the seminal works of Lykouris and Vassilvitskii [30] and Purohit *et al.* [35]. The focus, in this field, is on improving the algorithmic performance by leveraging some inherently imperfect *prediction* on the online input. This is in contrast to the standard framework of *competitive analysis* [15], in which the algorithm has no access to any information about the future, and the analysis is based on adversarial inputs tailored to the myopic nature of the algorithm.

Learning-augmented online algorithms are typically analyzed with respect to three performance metrics. The first is the *consistency* of the algorithm, namely its competitive ratio assuming that the prediction is error-free. The second is the *robustness*, that is, the competitive ratio assuming that the prediction is adversarial, and is thus generated by a malicious oracle. A third consideration is the degradation of the competitive ratio as a function of the prediction error; here, the notion of *smoothness* captures the requirement that the competitive ratio smoothly interpolates between the two extremes, namely the consistency and the robustness.

As expected, not all three objectives can be simultaneously optimized. Many works have thus focused on the trade-off between consistency and robustness. Algorithms with optimal tradeoffs are often called *Pareto-optimal* since their performance lies on the Pareto front of the two extreme metrics. Examples of problems studied in the Pareto setting include online conversion problems [37, 28], searching for a hidden target [4], ski rental [38, 8], online covering [14] metrical task systems [17], energy-minimization scheduling [27], scheduling [5, 7] and online state exploration [21].

Pareto-based analysis is attractive for several reasons. First, it fully characterizes the performance of the algorithm on the extreme scenarios, with respect to the reliability of the prediction. In addition, it provides a mathematically clean formulation of the desired objectives, which is often quite challenging even for seemingly simple online problems. However, as we will discuss, this type of analysis may very well suffer from *brittleness*, in that the performance ratio of any Pareto-optimal algorithm may be as high as its robustness, even if the prediction is near-perfect. This has an important implication for the algorithm designer: namely, in many realistic situations, a Pareto-optimal algorithm may perform even worse than the best competitive algorithm with no predictions.

To illustrate this drawback, as well as our proposed methodology for counteracting it, we will use the well-known *one-way trading* problem, which is one of the fundamental formulations for online financial transactions. In this problem, a decision maker must convert a unit in a given currency, say USD, to a different currency, say EUR, by performing exchanges over an unknown horizon. Specifically, prior to each transaction, the algorithm is informed about the current exchange rate, and must irrevocably exchange a fraction of its USD budget to EUR, according to the rate in question. This problem has served as a proving ground for the competitive analysis of more involved settings such as two-way trading and portfolio optimization; see, Chapter 14 in [15] and the survey [34]. In addition, it has connections to other problems such as fractional knapsack [16] and sponsored auctions [41]. Optimal competitive ratios, in the standard framework, were first obtained in [40]. An elegant Pareto-optimal algorithm for maximum-rate prediction was given in [37], based on the concept of an online *threshold* function. However, [37] does not take into consideration the prediction error other than at the two extreme values. In contrast, the interplay between the prediction error across the entire *spectrum* and the performance of the algorithm is at the heart of our study.

#### 1.1 Contribution

Our first result (Theorem 3.1) establishes the brittleness of all Pareto-optimal algorithms for one-way trading. To remedy this undesirable situation, in Section 3 we introduce the novel concept of a performance *profile* F, chosen by the end user. Informally, F maps the prediction error to an upper bound on the desired performance ratio of the algorithm. This concept is motivated by practical considerations in everyday applications. E.g., in financial markets, a trader may choose a customized profile based on historical stock exchange data, and how accurate past predictions have proven.

Naturally, not every profile may be *feasible*, in that there may not exist an online algorithm whose performance abides with it. Our next main result is an algorithm that decides whether a given profile is feasible (Theorem 3.2). Note that this is an *offline* problem, however, our algorithm also yields an online strategy, if F is indeed feasible. This further allows us to obtain an online algorithm that not only abides with a feasible profile F, but also with the "best" possible profile that has a shape similar to that of F (Remark 4.1). We formalize this intuitive notion based on the concept of the best vertical translation of F. We thus obtain a generalization of the concept of consistency (which is brittle) to the *consistency according to profile* F, which is inherently non-brittle by virtue of the profile definition.

In Section 5, we address another limitation of the known Pareto-optimal algorithms for one-way trading. Specifically, we note that the algorithm of [37] is tailored to worst-case inputs in which the exchange rates increase continuously until a certain point, then drop to the lowest rate. Again from a practical standpoint, such a worst-case scenario never arises in real markets. Motivated by the concept of the *lenient adversary* of [40] (in the standard, no-prediction setting), we present and analyze an *adaptive*, Pareto-optimal algorithm that leverages any deviation from the worst-case sequence to its benefit. To formally quantify the performance gain, we introduce an additional metric that captures the profit of the algorithm on all exchange rates that are at least as high as the predicted maximum rate, and allows us to compare any two Pareto-optimal algorithms via a *dominance* relation. Another novelty of our algorithm is that it does not require the prediction to be given ahead of time, instead the prediction can be revealed during its execution (Remark 5.1).

In Section 6 we give an experimental evaluation of all our algorithms, over both real data (Bitcoin exchange rates) and synthetic data, which validates the theoretical results and quantifies the obtained performance improvements. We emphasize that our framework can be readily applicable to other learning-augmented problems, in particular those which suffer from brittleness. We discuss another well-known application from AI, namely *contract scheduling* [5] in Section 7.

In terms of techniques, our algorithms and analysis are based on the concept of a *threshold* function which carefully guides the actions of the algorithm. While online threshold algorithms have been used in previous studies, including one-way trading [41, 39, 37, 28], the settings we study pose novel challenges. For the profile-based setting, the design of the function must take into consideration all the constraints induced by the profile. To this end, we use an iterative approach that considers the constraints incrementally, until they are all satisfied. For the adaptive setting, the threshold function must change dynamically, according to the revealed sequence. This is unlike the standard Pareto setting, in which a static function suffices.

Related work. There has been a significant body of recent work on online algorithms with predictions, see, e.g., the surveys [33, 32]. Several problems have been studied in learning-augmented settings, e.g., paging [30, 22], metrical task systems [9, 17], rent-or buy problems [35, 8, 19, 38, 2], packing and covering [14, 6, 20], scheduling [25, 27, 11, 31, 18, 24], matching [26, 10, 23], graph optimization [1, 3, 13, 12], and many others. This is only a partial list; for a comprehensive summary of the existing literature, we refer the reader to the online repository [29]. As discussed earlier, many works have focused exclusively on consistency/robustness tradeoffs, without an explicit error-based analysis, e.g. [37, 28, 4, 38, 8, 14, 17, 27, 5, 21, 1]. Incorporating smoothness in regards to the prediction error is a challenging task, both in terms of modeling and analysis. For instance, [12, 1] studied online combinatorial optimization problems in which the performance of the online degrades as a function of a distance measure between the predicted and the actual solution. Our work differs from such studies in that the dependency on the prediction error is *user specific*, and can change according to the application setting, while still maintaining the concepts of consistency and robustness.

#### 2 Preliminaries

In the one-way trading problem, the input σ is a sequence of *exchange rates*, where pi denotes the i-th rate in the sequence. The trader has a starting budget equal to 1. We follow the standard assumption that pi ∈ [1, M], where M represents an upper bound on the rates that is known in advance. Once pi is revealed, the trader must decide the amount to be exchanged to the secondary currency, which cannot exceed her current budget. We consider the general setting in which the horizon n is not known ahead of time. The problem formulation also assumes that the trader is notified once the last rate is revealed, and is thus obliged to exchange all of its remaining fund at rate pn.

An algorithm A decides the fractional exchanges upon revealing of pi , as a function of the previous i − 1 rates , i.e., the sequence σ[1, i − 1]. We denote by A(σ) the *profit* of A on σ, i.e., the total amount that A has produced after the last exchange. We denote by p ∗ σ = maxi∈[1,n] pi the *maximum* rate in σ and by OPT(σ) the profit of the optimal offline strategy, hence OPT(σ) = p ∗ σ . The competitive ratio of A is thus defined as CR(A) = supσ OPT(σ) A(σ) . For given σ, we refer to the ratio OPT(σ)/A(σ) as the *performance ratio* of A on σ. The optimal competitive ratio, denoted by r ∗ is Θ(log M), and more precisely, it is equal to the root of the equation r ∗ = ln M−1 r ∗−1 [40].

Given algorithm A, we denote by wA,i(σ) and sA,i(σ), the *budget* used by A and its accrued *profit* right before pi is revealed, respectively. We refer to wA,i(σ) as the *utilization* of A. Formally, for every sequence σ, and every algorithm A, we have wA,i = Pi−1 j=1 wA,j , with w1 = 0, and si = Pi−1 j=1 pj (wj+1 − wj ), with s1 = 0. For simplicity, we may omit the input σ, or the algorithm A when it is clear from context. For example, we will denote by p ∗ the maximum rate in σ.

The above definitions assume the standard setting in which the algorithm has no information on the input. In regards to learning-augmented settings, we consider the model of [37] in which the algorithm has an imperfect prediction pˆ on p ∗ . We define formally, the *consistency* and the robustness of an algorithm A as c(A) = supσ:p∗ σ=ˆp p ∗ σ A(σ) and r(A) = supσ suppˆ∈[1,M] p ∗ σ A(σ) , respectively. An algorithm A with prediction pˆ is *Pareto-optimal* if, for any given r, it has robustness at most r, and has the smallest possible consistency, which we will denote by c(r).

Remark 2.1 ([40]). It suffices to consider only sequences in which the exchange rates increase up to a certain point, then drop to 1. Moreover, for any competitively optimal algorithm, the worst-case inputs are such in which the exchange rates increase continuously, i.e., by infinitesimal amounts.

#### 3 Brittleness of Pareto-Optimal Algorithms and Performance Profiles

We first define formally the concept of *brittleness*.

Definition 3.1. Let pˆ denote a maximum-rate prediction for p ∗ σ . We say that pˆ is brittle if for any Pareto-optimal strategy A of robustness r and consistency c(r), and for every ϵ > 0, there exists σ with |pˆ − p ∗ σ | ≤ ϵ, for which p ∗ (σ) A(σ) = r.

The definition deems a prediction to be brittle if there exist sequences for which the slightest prediction error forces every Pareto-Optimal strategy to have a performance that is equal to its robustness.

Theorem 3.1 (Appendix A). The maximum-rate prediction is brittle for one-way trading.

Theorem 3.1 shows that Pareto-optimality is a very "fragile" metric for comparing strategies with max-rate prediction. To remedy this drawback, we introduce the new concept of a *profile*.

Definition 3.2. Let P be a partition of [1, M] to l intervals, i.e., P = Sl i=1[qi , qi+1), with q1 = 1 and ql+1 = M, and let pˆ be a maximum-rate prediction. A *profile* function F : P → R + is a step function that maps each interval in P to ti ∈ R +, and which satisfies the following conditions. There exists ˆı ∈ [1, l] such that: (i) ti−1 ≥ ti , for all i ≤ ˆı and ti+1 ≥ ti , for all i ≥ ˆı, and (ii) pˆ ∈ [qˆı , qˆı+1).

The profile function allows the end user to impose a requirement on the performance of the algorithm, as expressed in the following definition.

Definition 3.3. We say that an online strategy A *respects* a given profile F : Sl i=1[qi , qi+1) → R + if for all input sequences σ for which p ∗ σ ∈ [qi , qi+1), it holds that OPT(σ) A(σ) ≤ F([qi , qi+1)).

Informally, a profile F reflects a desired worst-case performance of an algorithm, assuming that the *actual* but unknown maximum rate in the input sequence is in the interval [qi , qi+1). Thus, the profile represents the desired upper bound on the performance of an algorithm, as a function of the prediction error. Unlike Pareto-optimality, which only cares about performance at extremes, the relation between performance and prediction error becomes now definable across the entire *spectrum* of error. The definition also reflects the expectation that the algorithm performs best when the prediction is error-free, and its performance degrades monotonically as a function of the error.

We illustrate the above concepts using the profile depicted in Figure 1a. Here, the profile consists of l = 6 intervals, where the first 3 intervals correspond to the *decreasing* part of the profile and the last 4 to the *increasing* part of the profile. Note that the interval [q3, q4) contains the prediction pˆ and belongs in both the decreasing and the increasing parts. Note also that the profile allows to define an asymmetric dependency on the prediction error. This is a very useful property in applications such as one-way trading. For example, a trader may want to be more cautious if the market will perform worse in the future, than better in the future, relative to what has been predicted.

Figure 1b depicts a different profile in which the performance ratio must be at most t1, for any error, unless the prediction is error-free, in which case the performance ratio has to be at most t2 < t1. Such a profile yields Pareto-optimality, if t1 = r and t2 = c(r).

We are interested in profiles F that are *feasible*, in the sense there exists an online algorithm that respects F. The following is one of our main results, whose proof will follow from Theorem 4.1 and Corollary 4.1, as we will show in Section 4.

Theorem 3.2. Given a profile F defined over l intervals, there exists an algorithm for deciding whether F is feasible that runs in time O(l). Furthermore, if F is feasible, there exists an *online* algorithm that respects F.

Given our algorithm that decides the feasibility of a profile, we can also answer a more general question. Suppose that F is infeasible, but we would like, nevertheless, to be able to respect a profile F ′ that is "similar" to F. Conversely, if F is feasible, then we know we can likely do even better, for example, we would like to follow a profile F ′ that is similar to F, but maps some intervals to smaller ratios. The following definition formalizes this intuitive objective.

Definition 3.4. Let F : P → R + denote a profile. Given a ∈ R +, we define the *extension* Ga of F as the vertical transformation of F, in which, for every interval [qi , qi+1) ∈ P it holds that Ga([qi , qi+1)) = a · F([qi , qi+1)).

![](_page_4_Figure_0.jpeg)

Figure 1: Illustration of profile functions.

We can generalize the concepts of consistency and robustness *relative to a profile* F as follows, recalling that pˆ ∈ [qˆı , qˆı+1).

Definition 3.5. Given a profile F for a prediction pˆ, and a robustness r, we say that algorithm A is r-robust and cconsistent *according to* F, if there exists an extension Ga of F for which: (i) for every interval, we have Ga([qi , qi+1)) ≤ r; (ii) Ga([qˆı , qˆı+1)) ≤ c; and (iii) A respects Ga.

Remark 3.1. The smoothness of a profile is related to the number of intervals, l. The larger the l, the smoother the performance of an algorithm which respects the profile.

#### 4 Profile-Based Algorithms

In this section, we present an algorithm which decides whether a given profile F is feasible or not. Note that this is an *offline*, decision problem, which we will denote by FEASIBLE(F ). In addition, if F is feasible, we also provide an *online* algorithm that respects F.

Our algorithms are inspired by the class of *threshold* algorithms (OTA), introduced in [41]. In these algorithms, a threshold function Φ guides the decision about the amount to be exchanged when a new rate is revealed. Specifically, Φ maps *utilization* to *reservation rates*. Here, a utilization value w ∈ [0, 1] represents the fractional amount exchanged so far by the online algorithm, whereas the reservation rate, ρ, is the minimum rate in [1, M] at which the algorithm will make an exchange. At each point a new rate pi is revealed, the algorithm updates its utilization by setting wi+1 = Φ−1 (pi), if pi > Φ(wi), otherwise wi+1 = wi . In both cases, it exchanges an amount equal to wi+1 − wi at rate pi . The function Φ must be increasing, and its codomain must include [1, M].

The main challenge posed in our setting is to guarantee the varying performance ratios globally, i.e., for all intervals and not just locally for a given interval. Thus, we need a global approach that takes into account the entirety of the profile, and in particular the transitions between consecutive intervals. We will thus design a function Φ so as to satisfy l set of constraints, where each set of constraints applies to a specific interval. Define s˜i = R wi 1 Φ(u)du, with s˜1 = 0. We seek a function Φ and values 0 = w1 ≤ . . . ≤ wl+1 ≤ 1 such that the following constraints are satisfied for all i ∈ [1, l].

$$\forall\beta\in[w_{i},w_{i+1}):\frac{\Phi(\beta)}{\bar{s}_{i}+\int_{w_{i}}^{\beta}\Phi(t)\,dt+1-\beta}\leq t_{i}.$$

$$[w_{i+1}]\Phi(w_{i+1})=q_{i+1}\cdotw_{i}\leq w_{i+1}\leq1$$

  
  
**[u]**  
  
$w_{i}\leq w_{i+1}\leq1$.  
  

Constraint [β] expresses the requirement on the performance ratio F([qi , qi+1)) that is imposed by the profile. Note that here s˜i is the minimum profit of an OTA at the point it reaches utilization wi . This follows from Remark 2.1. Constraint [wi+1] allows us to obtain the partition of the utilization levels induced by the profile. Moreover, such a constraint is needed for constraint [β] to correctly represent the performance ratio indicated by the profile. Constraint [u] establishes that the utilization levels defined are increasing and that they do not exceed the unit budget available to the algorithm. The following lemma follows straightforwardly from the above discussion.

Lemma 4.1. F is feasible if and only if there exist Φ and w1, . . . , wl+1 that satisfy the above sets of constraints, for all i ∈ [1, l].

Algorithm 1 Algorithm PROFILE for FEASIBLE (F); also an online strategy if F is feasible

Input: F : P = Sl i=1[qi , qi+1) → R +. Denote F([qi , qi+1)) by ti . 1: w1 ← 0, s ← 0 2: for i ∈ 1, . . . , l do 3: ρi ← ti · (s + 1 − wi) 4: if ρi ≥ qi then 5: wi+1 ← 1 ti · ln qi+1−1 ρi−1 + wi 6: Φi(w) ← Φi−1(w) if w ∈ [1, wi) (ρi − 1) · e ti·(w−wi) + 1 if w ∈ [wi , wi+1) 7: s ← s + R wi+1 wi Φi(t) dt 8: else 9: w ′ i ← qi−ti·(si−wiqi+1) tj ·(qi−1) 10: s ′ ← s + qi · (w ′ i − wi) 11: wi+1 ← 1 ti · ln qi+1−1 ti·(s ′+1−w′ i )−1 + w ′ i 12: Φi(w) ← Φi−1(w) if w ∈ [1, wi) (ti · (s ′ + 1 − w ′ i ) − 1) · e ti·(w−w ′ i ) + 1 if w ∈ [w ′ i , wi+1) 13: wi ← w ′ i 14: s ← s ′ + R wi+1 wi Φi(t) dt 15: if wl+1 > 1 then 16: return F is infeasible 17: else 18: return F is feasible and output Φl

Algorithm 1, which we call PROFILE, shows how to obtain the threshold function Φ, along with the utilization values w1, . . . wl+1, assuming that F is feasible. This is formally stated in Theorem 4.1. We emphasize that the theorem proves an even stronger statement; namely, if F is not feasible, then PROFILE correctly outputs its infeasibility. That is, the algorithm fully solves FEASIBLE(F ).

Theorem 4.1 (Appendix B). A profile F admits an online strategy which respects F if and only if PROFILE terminates with a value wl+1 ≤ 1.

Furthermore, if F is feasible, then PROFILE directly provides an online algorithm that respects F:

Corollary 4.1. If F is feasible, then the threshold function Φl returned by PROFILE defines an OTA which respects F.

Remark 4.1. For a profile F, we can use binary search in combination with PROFILE, in order to find the minimum a ∈ R +, such that Ga extends F and Ga is feasible, according to Definition 3.4.

We give some intuition about PROFILE, and how we obtain Φ, and the values wi , for all i. The algorithm computes Φ incrementally: namely, in iteration i, it obtains a new function Φi that aims to satisfy the sets of constraints for the intervals Si k=1[qk, qk+1), and computes a value for wi+1, as well as an updated value for wi . In each iteration i, the algorithm guarantees that an OTA based on Φi respects the profile on all sequences whose maximum rate is in [1, qi+1) (provided that this is indeed feasible) and, furthermore, that the utilization at the end of iteration i, namely wi+1 is as small as possible. This is crucial, since it allows us to decide FEASIBLE(F ) based on the final value of wl+1.

The algorithm makes a distinction between two types of updates. The first type occurs in the increasing part of the profile, i.e., when ti < ti−1. This is a relatively simpler case, because the algorithm has already guaranteed a smaller ratio in the previous interval. Hence the algorithm can afford to wait until it sees a rate that exceeds the reservation rate ρi (line 5-7). The second type occurs in the decreasing part of the profile (lines 9-14). This is intuitively a harder case, because on every new interval the algorithm must do even better than in the previous intervals. That is, when observing a rate equal to qi , the algorithm now needs to perform at a ratio ti < ti−1, hence it should have made a bigger profit. To this end, we need first to increase wi (lines 9 and 13) then extend Φi−1 to account for interval i (line 12). The precise amount by which we increase wi is guided by the requirement that the algorithm must have performance ratio ti for the worst-case sequence of increasing rates up to qi .

#### 5 An Adaptive Pareto-Optimal Algorithm

In this section we study another generalization of Pareto-optimality. The starting observation is that the Pareto-optimal OTA of [37] is tailored to worst-case scenarios. Namely, the threshold function in [37] is *static*, i.e., determined prior to the execution of the algorithm, and tailored to a sequence of continuously increasing exchange rates that may suddenly drop to 1. However, in practice, such sequences never occur in real markets. We show how to obtain an algorithm that is not only Pareto-optimal, but also leverages deviations from the worst-case sequence to its benefit.

Our setting is further motivated by [40], who studied the basic setting of standard competitive analysis without predictions. Their solution is based on *threat-based* policies, i.e., algorithms that exchange at each point in time the minimum required amount so as to guarantee the optimal competitive ratio. In this section, instead, we consider the learning-augmented setting in which the algorithm has access to a max-rate prediction pˆ. Our algorithm uses an *adaptive* threshold policy, in which the threshold function is updated every time a deviation from the worst-case input is observed. We follow this approach since OTAs are typically more versatile than threat-based policies, and can apply to more complex problems and settings, such as several variants of the knapsack problem, e.g., [39].

In a nutshell, we seek a Pareto-optimal algorithm that is not only optimal over worst-case sequences, but also over all other sequences. To describe this formally, we first define some concepts. Let pˆ be a max-rate prediction for an input σ of increasing rates, and define σ˜ as the suffix of σ comprised of rates at least as high as pˆ. (in the event that σ˜ is the empty sequence, our problem reduces to standard Pareto optimality). Let σ˜ = ˜p1, . . . , p˜m, and s˜i+1(A, σ) denote the profit made by an online algorithm A on σ after its exchange over rate p˜i , for any i ∈ [1, m], . Let also s(A, σ) denote the vector ⟨s˜i(A, σ)⟩ : i ∈ [1, m]. We say that algorithm A *dominates* another algorithm B on input σ, if s(A, σ) is lexicographically no smaller than s(B, σ).

| Algorithm 2 ADA-PO (adaptive Pareto-optimal) |
| --- |

```
Input: r ∈ R, pˆ ∈ [1, M]
1: w ← 0, s ← 0, p∗ ← 1
2: for pi ∈ σ do
3: if pi > p∗
            then
4: p
        ∗ ← pi
5: if pi ≤ pˆ then
6: wi+1 ← pi−r·(s+1−wpi)
                   r·(pi−1)
7: s ← s + pi
                  · (wi+1 − w)
8: w ← wi+1
9: else
10: if r · (s + 1 − pw + w
                          ∗
                           ) ≥ M then
11: wi+1 ← 1
12: else
13: wi+1 ← w
                    ∗
14: s ← s + pi
                  · (wi+1 − w)
15: w ← wi+1
```
Informally, s(A, σ) is the vector of profits that A has made so far, for each rate that is at least as high as the predicted maximum rate. The lexicographic ordering assigns priority to profits made at exchange rates close to, but larger than the prediction. We now state our main result.

Theorem 5.1 (Appendix C). For any robustness requirement r, ADA-PO is Pareto-optimal and dominates every other Pareto-optimal algorithm, on every possible sequence σ.

Note that the algorithm of [37] is dominant only for sequences in which the exchange rates increase continuously up to some p ∗ ≥ pˆ, then drop to 1. For those and all other sequences, our algorithm dominates that of [37]. Note also that a dominant r-robust algorithm is a Pareto-optimal algorithm.

ADA-PO consists of two phases. The first phase (lines 5-9) consists of revealed rates strictly smaller than pˆ. In this phase, the algorithm exchanges the minimum amounts so as to guarantee r-robustness (i.e., it makes threat-based decisions). Here, adaptivity allows the algorithm to reserve its budget for the second phase. The second phase (lines 11-15) consists of revealed rates at least as high as pˆ. This is the challenging part, since we need to ensure simultaneously dominance and r-robustness, but these two objectives are in a trade-off relation. Here, adaptivity allows us to exchange more money at each revealed rate without sacrificing robustness.

Suppose that pi is revealed in the second phase (i.e., pi ≥ pˆ). To achieve simultaneously the robustness and the dominance, we need to find a continuous increasing Φ whose domain is [wi+1, 1], along with a value for wi+1. To this end, we solve the optimization problem Oi , described below.

Here, constraint [β] is for guaranteeing r-robustness; and constraint [M] and [u] guarantee that Φ is well-defined as a threshold function. Maximizing w maximizes the amount exchanged at rate pi , which is essential for dominance. In Appendix C we give further details, and we show that Oi has optimal solution w ∗ equal to the root of the equation w ∗ = 1 − 1 r ln M−1 r(si+1−piwi+w∗(pi−1)−1) , which is used in line 13 of ADA-PO.

$$\begin{array}{ll}\max&w\\ \mbox{subj,to}&\\ \{\beta\}&\forall\beta\in[w,1):\frac{\Phi(\beta)}{s_{i}+p_{i}\cdot(w-w_{i})+\int_{w}^{\beta}\Phi(t)\,dt+1-\beta}=r,\\ \{M\}&\Phi(1)\geq M,\\ \{\bf u\}&w_{i}\leq w\leq1.\end{array}$$

Remark 5.1. ADA-PO, unlike the known static OTAs, does not require a prediction pˆ ahead of time; the prediction can be revealed during its execution instead, since it is only used in the second phase. This can be very useful in practice, e.g., if the trader obtains information "on-the-fly".

#### 6 Experimental evaluation

We present experimental results for both the profile-based algorithm PROFILE (Algorithm 1) and the adaptive Paretooptimal algorithm ADA-PO (Algorithm 2). We compare our algorithms to the state of the art Pareto-optimal algorithm of [37], which we denote by PO.

Profile setting. We use a profile F that consists of three intervals [q1 = 1, q2), [q2, q3) and [q3, q4 = M], where M = 100. The profile is defined in terms of the prediction pˆ, by choosing q2 = 0.9ˆp and q3 = 1.1ˆp. In addition, F is such that F([q1, q2)) = t1 = F([q3, q4]) = t3 = r, where r = 4 (larger than, but close to the optimal competitive ratio r ∗ ). Here, F([q2, q3)) = t2 < r is the *smallest* value such that F is feasible. To find t2, we use binary search in [1, r] in combination with PROFILE, and note that this depends on pˆ. F is depicted in Figure 2a. Intuitively, r corresponds to the robustness, whereas t2 is the performance ratio if the input σ is such that p ∗ ∈ [0.9ˆp, 1.1ˆp), i.e. if pˆ is "close" to p ∗ . The length of [q2, q3), which is equal to 0.2ˆp, reflects how much the user trusts the prediction.

Figure 2b depicts the performance of PROFILE, and PO with robustness r, on the worst case sequences of maximum rate p ∗ , as a function of p ∗ . Recall that such sequence is of the form 1, . . . , p∗ , 1, with infinitesimal increments up to p ∗ , simulated using a step equal to 0.01. We denote this sequence by σ w p∗ . We choose pˆ u.a.r. in [1, M] (pˆ = 67.8 in Figure 2b). We observe that PO exhibits high brittleness if p ∗ is very close, but smaller than pˆ, namely has performance ratio of r, which validates Theorem 3.1. In contrast, PROFILE guarantees a performance ratio equal to t2 in the entire interval [0, 9ˆp, 1.1ˆp], as required by F, thus tolerating a prediction error as high as 10%, while remaining r-robust for all errors. This validates Theorem 4.1. As expected, PO has better ratio if p ∗ = ˆp (from the definition of Pareto optimality).

To further quantify the performance difference between the two algorithms, we evaluated both algorithms on 100 randomly defined worst-case sequences. Each sequence σ w p∗ is obtained by sampling pˆ u.a.r. in [1, M], and for such pˆ, by randomly picking p ∗ ∈ [0.9ˆp, 1.1ˆp], the significant prediction error for the user. Figure 2c depicts the relative performance difference of the two algorithms for each σ w p∗ , as a function of the prediction error. We observe that if p ∗ < pˆ, then PROFILE improves upon PO by 20% to 50% , whereas if p ∗ > pˆ, PROFILE is inferior by only 10% to 20%. The average improvement we report, taken over the 100 ratios is 22%. We conclude that while both algorithms guarantee robustness r, PROFILE is not only smooth around the prediction, but also performs better on the average, which supports the benefits from using a profile.

In addition, we performed experiments over sequences obtained from real trading data, using the profile F as above. We used exchange rates from Bitcoin (BTC) to USD; specifically, we used a list of the last 1000 daily exchange rates (finishing on May 20, 2024), defining as the prediction pˆ the maximum rate in the first 200 rates, and running the algorithm on a sequence consisting of the last 800 rates. Figure 2d depicts the performance ratios of PROFILE and PO, where each point in the plot corresponds to the maximum rate observed so far: these are the only rates at which the algorithms make exchanges. We observe that PO continues to suffer from brittleness, whereas PROFILE still exhibits smooth degradation in the interval [0.9ˆp, 1.1ˆp].

In Appendix E we report an additional experiment on the average performance over BTC sequences. The key takeaway from all experiments on both synthetic and real sequences is that PROFILE performs much better if p ∗ < pˆ, and at the same time it is only slightly worse, if p ∗ > pˆ. This behavior is due to the smoothness enforced around the prediction, as guaranteed by the profile.

Adaptive setting. Since, by definition, PO and ADA-PO perform the same over worst-case sequences, we focus on sequences from BTC rates. Based on a list of the last 1000 daily BTC rates, we obtain a prediction pˆ and the sequence, as in our profile-based experiments above. Figure 2e plots the performance ratio as a function of the currently observed maximum rate in the sequence. For every such rate that exceeds pˆ, ADA-PO outperforms PO, which validates Theorem 5.1. This comes at an unavoidable increase in brittleness, as expected, and illustrates the tradeoff between smoothness and dominance. We expect ADA-PO to be the algorithm of choice when the prediction is conservative, or when pˆ is not given to the trader ahead of time, but is rather revealed at some point in the sequence.

![](_page_8_Figure_2.jpeg)

Figure 2: Summary of the experimental results.

#### 7 Discussion

Our profile-based framework can apply to many other problems augmented with ML predictions, and is not specific to one-way trading. To illustrate this, in Appendix D we analyze another application in the context of *contract scheduling*, which is a classic problem from resource-bounded reasoning in AI, and which, likewise, suffers from brittleness. Our work is the first towards understanding the power and limitations of imperfect ML predictions in competitive financial optimization beyond extreme values of the prediction error. The techniques introduced will help address problems such as two-way trading and portfolio optimization, which have not yet been studied in learning augmented settings. Other potential applications include several well-known variants knapsack problems, where online threshold algorithms are commonly used, especially in learning-augmented settings [16, 39].

#### Acknowledgement

This work was funded by the project PREDICTIONS, grant ANR-23-CE48-0010 from the French National Research Agency (ANR)

#### References

- [1] Matteo Almanza et al. "Online Facility Location with Multiple Advice". In: *Advances in Neural Information Processing Systems , NeurIPS 2021*. 2021, pp. 4661–4673.
- [2] Keerti Anand, Rong Ge, and Debmalya Panigrahi. "Customizing ML Predictions for Online Algorithms". In: *Proceedings of the 37th International Conference on Machine Learning, ICML*. Vol. 119. Proceedings of Machine Learning Research. PMLR, 2020, pp. 303–313.
- [3] Keerti Anand et al. "Online Algorithms with Multiple Predictions". In: *International Conference on Machine Learning, ICML*. Vol. 162. Proceedings of Machine Learning Research. PMLR, 2022, pp. 582–598.
- [4] Spyros Angelopoulos. "Online search with a hint". In: *Inf. Comput.* 295.Part B (2023), p. 105091.
- [5] Spyros Angelopoulos and Shahin Kamali. "Contract Scheduling with Predictions". In: *J. Artif. Intell. Res.* 77 (2023), pp. 395–426.
- [6] Spyros Angelopoulos, Shahin Kamali, and Kimia Shadkami. "Online Bin Packing with Predictions". In: *Journal of Artificial Intelligence Research* 78 (2023), pp. 1111–1141.
- [7] Spyros Angelopoulos et al. "Contract Scheduling with Distributional and Multiple Advice". In: *Proceedings of the 33rd International Joint Conference on Artificial Intelligence (IJCAI)*. arXiv:2404.12485. 2024.
- [8] Spyros Angelopoulos et al. "Online Computation with Untrusted Advice". In: *11th Innovations in Theoretical Computer Science Conference, ITCS*. Ed. by Thomas Vidick. Vol. 151. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2020, 52:1–52:15.
- [9] Antonios Antoniadis et al. "Online Metric Algorithms with Untrusted Predictions". In: *ACM Trans. Algorithms* 19.2 (2023), 19:1–19:34.
- [10] Antonios Antoniadis et al. "Secretary and online matching problems with machine learned advice". In: *Discret. Optim.* 48.Part 2 (2023), p. 100778.
- [11] Yossi Azar, Stefano Leonardi, and Noam Touitou. "Flow time scheduling with uncertain processing time". In: *STOC '21: 53rd Annual ACM SIGACT Symposium on Theory of Computing*. Ed. by Samir Khuller and Virginia Vassilevska Williams. ACM, 2021, pp. 1070–1080.
- [12] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. "Discrete-Smoothness in Online Algorithms with Predictions". In: *Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS*. 2023.
- [13] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. "Online Graph Algorithms with Predictions". In: *Proceedings of the 2022 ACM-SIAM Symposium on Discrete Algorithms, SODA*. Ed. by Joseph (Seffi) Naor and Niv Buchbinder. SIAM, 2022, pp. 35–66.
- [14] Etienne Bamas, Andreas Maggiori, and Ola Svensson. "The primal-dual method for learning augmented algorithms". In: *Advances in Neural Information Processing Systems* 33 (2020), pp. 20083–20094.
- [15] Allan Borodin and Ran El-Yaniv. *Online computation and competitive analysis*. Cambridge University Press, 1998.
- [16] Ying Cao, Bo Sun, and Danny H.K. Tsang. "Optimal Online Algorithms for One-Way Trading and Online Knapsack Problems: A Unified Competitive Analysis". In: *2020 59th IEEE Conference on Decision and Control (CDC)*. 2020, pp. 1064–1069. DOI: 10.1109/CDC42340.2020.9303856.
- [17] Nicolas Christianson, Junxuan Shen, and Adam Wierman. "Optimal robustness-consistency tradeoffs for learningaugmented metrical task systems". In: *AISTATS*. Vol. 206. Proceedings of Machine Learning Research. PMLR, 2023, pp. 9377–9399.
- [18] Franziska Eberle et al. "Speed-robust scheduling: sand, bricks, and rocks". In: *Math. Program.* 197.2 (2023), pp. 1009–1048.
- [19] Sreenivas Gollapudi and Debmalya Panigrahi. "Online Algorithms for Rent-Or-Buy with Expert Advice". In: *Proceedings of the 36th International Conference on Machine Learning, ICML*. Vol. 97. Proceedings of Machine Learning Research. PMLR, 2019, pp. 2319–2327.
- [20] Elena Grigorescu et al. "Learning-Augmented Algorithms for Online Linear and Semidefinite Programming". In: *Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022*. 2022.
- [21] Sungjin Im et al. "Online State Exploration: Competitive Worst Case and Learning-Augmented Algorithms". In: *ECML/PKDD (4)*. Vol. 14172. Lecture Notes in Computer Science. Springer, 2023, pp. 333–348.
- [22] Sungjin Im et al. "Parsimonious Learning-Augmented Caching". In: *International Conference on Machine Learning, ICML*. Vol. 162. Proceedings of Machine Learning Research. PMLR, 2022, pp. 9588–9601.
- [23] Zhihao Jiang et al. "Online Selection Problems against Constrained Adversary". In: *Proceedings of the 38th International Conference on Machine Learning, ICML*. Vol. 139. Proceedings of Machine Learning Research. PMLR, 2021, pp. 5002–5012.
- [24] Alexandra Anna Lassota et al. "Minimalistic Predictions to Schedule Jobs with Online Precedence Constraints". In: *ICML*. Vol. 202. Proceedings of Machine Learning Research. PMLR, 2023, pp. 18563–18583.
- [25] Silvio Lattanzi et al. "Online Scheduling via Learned Weights". In: *Proceedings of the 2020 ACM-SIAM Symposium on Discrete Algorithms*. SIAM, 2020, pp. 1859–1877.
- [26] Thomas Lavastida et al. "Learnable and Instance-Robust Predictions for Online Matching, Flows and Load Balancing". In: *29th Annual European Symposium on Algorithms, ESA)*. Vol. 204. LIPIcs. 2021, 59:1–59:17.
- [27] Russell Lee et al. "Online Peak-Aware Energy Scheduling with Untrusted Advice". In: *e-Energy*. ACM, 2021, pp. 107–123.
- [28] Russell Lee et al. "Online Search with Predictions: Pareto-optimal Algorithm and its Applications in Energy Markets". In: *e-Energy*. ACM, 2024, pp. 50–71.
- [29] Alexander Lindermayr and Nicole Megow. *Repository of works on algorithms with predictions*. https:// algorithms-with-predictions.github.io. Accessed: 2023-12-01. 2023.
- [30] Thodoris Lykouris and Sergei Vassilvitskii. "Competitive Caching with Machine Learned Advice". In: *J. ACM* 68.4 (2021), 24:1–24:25. DOI: 10.1145/3447579. URL: https://doi.org/10.1145/3447579.
- [31] Michael Mitzenmacher. "Scheduling with Predictions and the Price of Misprediction". In: *11th Innovations in Theoretical Computer Science Conference, ITCS*. Vol. 151. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2020, 14:1–14:18.
- [32] Michael Mitzenmacher and Sergei Vassilvitskii. "Algorithms with Predictions". In: *Beyond the Worst-Case Analysis of Algorithms*. Cambridge University Press, 2020, pp. 646–662.
- [33] Michael Mitzenmacher and Sergei Vassilvitskii. "Algorithms with predictions". In: *Commun. ACM* 65.7 (2022), pp. 33–35.
- [34] Esther Mohr, Iftikhar Ahmad, and Günter Schmidt. "Online algorithms for conversion problems: a survey". In: *Surveys in Operations Research and Management Science* 19.2 (2014), pp. 87–104.
- [35] Manish Purohit, Zoya Svitkina, and Ravi Kumar. "Improving Online Algorithms via ML Predictions". In: *Advances in Neural Information Processing Systems*. Vol. 31. 2018, pp. 9661–9670.
- [36] Stuart J. Russell and Shlomo Zilberstein. "Composing real-time systems". In: *Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI)*. 1991, pp. 212–217.
- [37] Bo Sun et al. "Pareto-optimal learning-augmented algorithms for online conversion problems". In: *Advances in Neural Information Processing Systems* 34 (2021), pp. 10339–10350.
- [38] Alexander Wei and Fred Zhang. "Optimal Robustness-Consistency Trade-offs for Learning-Augmented Online Algorithms". In: *Proceedings of the 33rd Conference on Neural Information Processing Systems (NeurIPS)*. 2020.
- [39] Lin Yang et al. "Competitive algorithms for online multidimensional knapsack problems". In: *Proceedings of the ACM on Measurement and Analysis of Computing Systems* 5.3 (2021), pp. 1–30.
- [40] Ran El-Yaniv et al. "Optimal search and one-way trading online algorithms". In: *Algorithmica* 30.1 (2001), pp. 101–139.
- [41] Yunhong Zhou, Deeparnab Chakrabarty, and Rajan Lukose. "Budget constrained bidding in keyword auctions and online knapsack problems". In: *Proceedings of the 17th international conference on world wide web*. 2008, pp. 1243–1244.

## Appendix

#### A Details from Section 3

*Proof of Theorem 3.1.* Let A be a Pareto-optimal algorithm of robustness r, and consistency c(r). We will show that for any fixed ϵ > 0, there exists a sequence σ and a prediction pˆ such that η = |pˆ− p ∗ σ | ≤ ϵ, and A satisfies Definition 3.1. Since A is Pareto-optimal, there exists a non-empty set of sequences Σc, such that for all σc ∈ Σc, if A is given as prediction p ∗ σc , then

$$\frac{p_{\sigma_{c}}^{*}}{A(\sigma_{c})}=c(r).$$

As shown in [40] we can assume, without loss of generality, that every σc is increasing, i.e., it is of the form σc = p1, . . . , pk, p∗ σc with pi > pj , for all i < j, and p ∗ σc > pk. We define Σ to be the co-domain of the following function, f:

$f:\Sigma_{c}\rightarrow\Sigma$ such that $f(\sigma_{c})=\begin{cases}\sigma_{c}&\text{if}|p_{\sigma_{c}}^{*}-p_{k}|\leq\epsilon,\\ p_{1},\ldots,p_{k},p_{\sigma_{c}}^{*}-\epsilon,p_{\sigma_{c}}^{*}&\text{otherwise}.\end{cases}$ (A.1)

Given a σ ∈ Σ, let n = |σ| − 1, and let xn be the fraction exchanged by A. Since A is r-robust, it needs to account for the scenario in which the adversary chooses to drop all rates to 1 after exchanging at the rate pn. Thus, xn must satisfy

$$\frac{p_{n}}{s_{n}+p_{n}\cdot x_{n}+1-x_{n}-w_{n}}\leq r,$$
  
  

$$\cdot\quad p_{n}-r\cdot(s_{n}+1-w_{n})\tag{1.2}$$

or equivalently,

$$x_{n}\geq\frac{p_{n}-r\cdot(s_{n}+1-w_{n})}{r\cdot(p_{n}-1)}.$$
 (A.2)

Define ω to be the RHS of (A.2) Suppose first, that there exists a sequence σ ∈ Σ for which A exchanges xn = ω. In this case, if A is given a prediction pˆ = p ∗ σ , then for the the sequence σr = σ[1, n] we have that |pˆ− p ∗ σr | ≤ ϵ, and:

$$\frac{p_{\sigma_{r}}^{*}}{A(\sigma_{r})}=\frac{p_{n}}{s_{n}+p_{n}\cdot\omega+1-\omega-w_{n}}=r,$$

and the proof is complete in this case.

It thus remains to consider the case that for all σ ∈ Σ, xn > ω. Let xn+1 be the amount exchanged by A at rate p ∗ σ . We define an online algorithm A′ , whose statement is given in Algorithm 3. Intuitively, while the rate is below p ∗ σ , A′ makes the same decisions as A. If the rate is between p ∗ σ − ϵ and p ∗ σ , A′ exchanges ω. If the rate is precisely p ∗ σ A′ exchanges xn plus what A did not exchange on rates which were between p ∗ σ − ϵ and p ∗ σ . Finally, A′ makes the same decisions as A for all rates that exceed p ∗ σ . We will show that A′ has robustness at most r and consistency cA′ such that cA′ < c(r), which contradicts that A is Pareto-optimal.

We first show that A′ is r-robust. Let σ ′ be an input sequence and pˆ a prediction given to A′ , we will show that p ∗ σ′ ≤ rA(σ ′ ). If p ∗ σ′ < pˆ− ϵ, then has A′ made the same decisions as A, hence remains r-robust. If pˆ− ϵ < p∗ σ′ < pˆ, then by definition of ω, A′ is guaranteed to be r-robust. Last, if p ∗ σ′ ≥ pˆ, then A′ achieves a strictly better profit than A.

It remains to show that A′ has consistency strictly smaller than c(r). To this end, it suffices to show that: (i) for all σc ∈ Σc it holds that OPT(σc) A′(σc) < c(r), and that (ii) for all σ ′ ∈/ Σc it holds that OPT(σc) A′(σc) < c(r), assuming that both A and A′ are given a prediction pˆ = p ∗ σ′ .

To show (i), note that for σ ′ ∈ Σc it holds that OPT(f(σ ′ )) A(f(σ′)) < c(r), due to A exchanging xn > ω and A′ exchanging xn = ω. If f(σ ′ ) = σ ′ (first case in (A.1)) then OPT(σ ′ ) A(σ′) < c(r). Otherwise, (second case in (A.1)) A(σ ′ ) > A(f(σ ′ )) hence the same result holds. To show (ii), observe that A′ (σ ′ ) > A(σ ′ ) due to A exchanging xn > ω and A′ exchanging xn = ω. Hence, by the definition of Σc, we have

$${\frac{\mathrm{OPT}(\sigma_{c})}{A^{\prime}(\sigma_{c})}}<{\frac{\mathrm{OPT}(\sigma_{c})}{A(\sigma_{c})}}<c(r),$$

which concludes the proof.

Algorithm 3 Statement of the online algorithm A′

Input: Algorithm A, p, ϵ ˆ 1: p ∗ = 1, e ← 0 2: for each rate pi in the input sequence do 3: if pi > p∗ then 4: p ∗ ← pi 5: if pi < pˆ− ϵ then 6: Exchange the same amount as A 7: else if pˆ− ϵ < pi < pˆ then 8: Exchange ω 9: e ← e + xi − ω 10: else if pi = ˆp then 11: Exchange xn + e 12: else 13: Exchange the same amount as A

#### B Details from Section 4

In this section, we show how to compute the function Φ used in PROFILE (Algorithm 1), for deciding whether a profile F is feasible. Recall that we seek a function Φ and values 0 = w1 ≤ . . . ≤ wl+1 ≤ 1 that satisfy the following sets of constraints.

$$\forall\beta\in[w_{i},w_{i+1}):\frac{\Phi(\beta)}{s_{i}+\int_{w_{i}}^{\beta}\Phi(t)\,dt+1-\beta}\leq t_{i}$$

$$[w_{i+1}]\Phi(w_{i+1})=q_{i+1}w_{i}\leq w_{i+1}\leq1$$

$$|\mathbf{u}|$$

for each rate interval [qi , qi+1).

As explained in Section 4, our algorithm builds a function Φ and values wi in an iterative way. That is, it processes each set of constraints iteratively, and at each step j ∈ [1, l] it builds a function Φj and computes values w1, . . . , wj+1 which satisfy the sets of constraints for all intervals [qi , qi+1) with i ≤ j. Each function Φj and the new values w1, . . . , wj+1 are a function of Φj−1 and the previous values w1, . . . , wj+1.

We explain an iteration of this process. Suppose that the algorithm is at a step where it has computed Φj−1 and values w1, . . . , wj as to satisfy the sets of constraints for the intervals [qi , qi+1) with i < j. Constraint [β] requires us to guarantee a ratio of at least tj for every sequence whose maximum rate is in [qj , qj+1). We derive a function which achieves a ratio *equal* to tj for such sequences. The equality is sought, instead of the inequality, in order to minimize utilization. Intuitively, enforcing a ratio smaller than tj would force the algorithm to exchange more money to achieve a bigger profit. Thus the following constraint

$$\forall\beta\in[w_{j},w_{j+1}):{\frac{\Phi(\beta)}{s_{j}+\int_{w_{j}}^{\beta}\Phi(t)\,d t+1-\beta}}=t_{j},$$

from which we can obtain the differential equation:

$\dot{\Phi}=t_{j}\cdot\Phi-t_{j}$, (B.1)

which is a separable first order differential equation. We can hence find the unique solution

$$\Phi(\beta)=C\cdot e^{t_{j}\cdot\beta}+1.$$

We then apply constraint [β], for an arbitrary β ∈ [wj , wj+1), so to find the value of the constant C, which yields

$$\Phi(\beta)=(t_{j}\cdot(s_{j}+1-w_{j})-1)\cdot e^{t_{j}\cdot(\beta-w_{j})}+1\,$$
 (B.2)

The obtained function is the unique solution to such an equation. We denote ρj = tj · (sj + 1 − wj ).

We then use constraint [wj+1] to find an expression for wj+1:

$$w_{j+1}=\frac{1}{t_{j}}\ln\left(\frac{q_{j+1}-1}{\rho_{j}-1}\right)+w_{j}$$
 (B.3)

Note that Φ(wj ) = ρj . There are two cases to be analyzed.

First, if ρj > qj , then we can define Φj as follows:

$$\Phi_{j}(w)={\begin{cases}\Phi_{j-1}(w)&{\text{if}w\in[1,w_{j})}\\ (t_{j}\cdot(s_{j}+1-w_{j})-1)\cdot e^{t_{j}\cdot(\beta-w_{j})}+1&{\text{if}w\in[w_{j},w_{j+1}),}\end{cases}}$$

where wj+1 is defined in (B.3). We say that we extend the previous Φj−1. This scenario materializes when the algorithm has achieved a profit sj , which allows it to not exchange while observing rates in [qj , ρj ] and still remain tj -competitive. This occurs when tj > tj−1, hence it occurs for the increasing part of the profile.

On the other hand, ρj < qj , if tj < tj−1. If this case occurs, the algorithm has not obtained a sufficient profit to be tj -competitive when presented with the sequence which continuously increases from 1 to qj , which is the worst-case sequence as stated in Remark 2.1. As we will show in the proof of Theorem 4.1 wj is the least utilization that can be spent so to satisfy every set of constraints [qk, qk+1) with k < j. To enforce a ratio of tj and still minimize utilization, the algorithm must exchange a bigger amount when rate qj is revealed, since exchanging more at a lower rate would lead to a larger utilization. To guarantee a ratio of tj for the continuous increasing sequence, the algorithm should trade an amount equal to w ′ j − wj , where w ′ j is obtained from:

$$\frac{q_j}{s_j+q_j\cdot(w'_j-w_j)+1-w'_j}=t_j,$$
  

$$c_j=t_j\cdot(c_j-w_j c_j+1)$$

and leads to

$$w_{j}^{\prime}={\frac{q_{j}-t_{j}\cdot(s_{j}-w_{j}q_{j}+1)}{t_{j}\cdot(q_{j}-1)}}.$$

We now wish to extend function Φj−1, obtained in the previous iteration, so as to satisfy all constraints for interval [qj , qj+1). Let s ′ j = sj + qj ·(w ′ j − wj ), which is the profit obtained by the OTA in the worst case where the maximum rate is qj . We may express this problem by a new set of constraints, which are:

$$\forall\beta\in[w^{\prime}_{j},w_{j+1}):\frac{\Phi(\beta)}{s^{\prime}_{j}+\int_{w^{\prime}_{j}}^{\beta}\Phi(t)\,dt+1-\beta}\leq t_{j},$$

$$[w_{j+1}]$$

$$w^{\prime}_{j}\leq w_{j+1}\leq1.$$

Note that this set of constraints is the same as the ones we started with, but sj was replaced by s ′ j and wj by w ′ j . Hence, the Φ and wj+1 which satisfy the constraints and minimize wj+1 are:

$$\Phi(\beta)=(t_{j}\cdot(s^{\prime}_{j}+1-w^{\prime}_{j})-1)\cdot e^{t_{j}\cdot(\beta-w^{\prime}_{j})}+1,$$
 (B.4)

$$w_{j+1}=\frac{1}{t_{j}}\ln\left(\frac{q_{j+1}-1}{t_{i}\cdot(s^{\prime}+1-w_{i}^{\prime})-1}\right)+w_{j}^{\prime}.$$
 (B.5)

.

We can now proceed with the proof for Theorem 4.1.

*Proof of Theorem 4.1.* As stated in Remark 2.1, every online strategy will exchange on rates which are best-seen so far. We can hence state every strategy as an OTA. It suffices then to prove the following: There exists an OTA which respects F if and only if PROFILE terminates with a value wl+1 ≤ 1.

Let F be a performance profile. The if direction follows directly from the design of PROFILE. It suffices to observe that the obtained function Φl can be used as the threshold function for an OTA which respects the profile F.

To prove the only if direction, we will prove that every wi obtained by PROFILE is the least utilization needed to satisfy all sets of constraints for intervals [qk, qk+1) for k < i. In other words, we will prove that if A is an OTA, which respects F, defined by Φ, and where w ′ 1 , . . . , w′ l+1 are the respective utilization levels reached by A when observing rates q1, . . . , ql+1, i.e: Φ(w ′ i ) = qi for each i ∈ [1, . . . , l + 1], then wi ≤ w ′ i . This statement follows, once again, from the design of PROFILE. By replacing the inequality constraint in [β] by an equality, we manage to achieve a ratio which is exactly the one demanded by the profile, hence reserving budget for futures rates. PROFILE obtains a function Φl which enforces, for each i ∈ [1, l] and for each q ∈ [qi , qi+1) the equation:

$$\frac{q}{\int_{1}^{\Phi_{l}^{-1}(q)}\Phi_{l}(u)d u+1-\Phi_{l}^{-1}(q)}=t_{i}$$

We conclude that PROFILE minimizes utilization while satisfying every set of constraints, thus proving the theorem.

Figure 3 illustrates PROFILE. Here we observe that for the increasing part of the profile, Φi with i ∈ [4, 7] extends Φi−1 with an exponential function starting at wi , where Φi(wi) > Φi−1(wi). Here the vertical "jumps" reflect the less stringent requirement in the increasing part (we can afford to reserve our budget for later). For the decreasing part of the profile, Φi with i ∈ [1, 3] extends Φi−1 with an exponential function starting at w ′ i > wi (line 9 in the statement) where Φi(w ′ i ) = Φi−1(wi), which is reflected in the presence of straight lines in Figure 3.

![](_page_14_Figure_1.jpeg)

Figure 3: An illustration of PROFILE. Here the profile F is as follows: F([1, 20) = 7,F([20, 35]) = 5, F([35, 50]) = 3, F([50, 70]) = 3.5, and F([70, 100]) = 4 .

#### C Details from Section 5

In this section, we detail the calculations that lead to the value wi+1, which is the maximum an online algorithm can spend on rate pi while ensuring r-robustness.

The aforementioned wi+1 is the solution to the following optimization problem:

| max |  | w |  |  | (Oi) |
| --- | --- | --- | --- | --- | --- |
| subj. to |  |  |  |  |  |
| [β] | = r, | Φ(β) | ∀β ∈ [w, 1) : |  |  |
|  |  | · (w − wi) + R β w Φ(t) dt + 1 − β |  | + pi |  |
| [u] |  | wi ≤ w ≤ 1. |  |  |  |
|  |  | si |  |  |  |
| [M] |  | Φ(1) ≥ M, |  |  |  |

From constraint [β], we do the same analysis as in B to find Φ(β) = C · e rβ + 1. Once again, to find the constant C we use constraint [β] for an arbitrary value β ∈ [wi+1, 1], which leads to:

$\Phi(\beta)=\left(r\cdot(s_{i}+1-p_{i}w_{i}+w_{i+1}\cdot(p_{i}-1))-1\right)\cdot e^{r\cdot(\beta-w_{i+1})}+1$.  
  

We then use constraint [M] to obtain an upper bound on wi+1:

$(r\cdot(s_{i}+1-p_{i}w_{i}+w_{i+1}\cdot(p_{i}-1))-1)\cdot e^{r\cdot(1-w_{i+1})}+1\geq M,$

which leads to:

$$w_{i+1}\leq1-{\frac{1}{r}}\ln\left({\frac{M-1}{r(s_{i}+1-p_{i}w_{i}+w_{i+1}(p_{i}-1)-1)}}\right)$$

.

Thus the largest value of wi+1 is the root of the equation

$$w_{i+1}=1-\frac{1}{r}\ln\left(\frac{M-1}{r(s_{i}+1-p_{i}w_{i}+w_{i+1}(p_{i}-1)-1)}\right),$$

which can be solved using numerical methods. Let ρ be the reservation rate for utilization wi+1, then

$\rho=\Phi(w_{i+1})=r\cdot(s_{i}+1-p_{i}w_{i}+w_{i+1}\cdot(p_{i}-1))$.  
  

If ρ > M, then the algorithm has achieved a sufficient profit to guarantee r-robustness independently of future rates. Hence, to maximize wi+1, we can safely set it to 1. However, if ρ < M, then constraint [M] was saturated, and the algorithm will achieve a performance ratio of r for every sequence which grows continuously from ρ until a rate p ∗ ∈ [ρ, M]. Moreover, for every sequence whose maximum rate p ∗ ∈ [pi , ρ) the algorithm will have a performance ratio smaller than r.

As explained in Appendix B using constraint [β] with an equality allows us to guarantee a performance ratio of r minimizing utilization. Observe that to maximize wi+1 we need to minimize the left-over budget to remain r-robust in the future. We can hence conclude that wi+1 − wi is indeed the largest amount of money we can exchange at rate pi and remain r-robust.

We will next provide the proof for Theorem 5.1.

*Proof of Theorem 5.1.* We are to prove that ADA-PO is Pareto-Optimal and dominates every other Pareto-Optimal algorithm on any sequence σ.

First, we will prove that ADA-PO is Pareto-Optimal. Let r be a a robustness requirement, and c(r) the respective consistency. To start with, we prove that ADA-PO is r-robust. Consider first the (easy) case where p ∗ < pˆ then ADA-PO assures a performance ratio of r using the threat-based approach.

Consider then the (harder) case in which p ∗ > pˆ. Let pi be the first rate above pˆ and wi+1,Φi be the respective solution to problem Oi . We must prove that no matter how the sequence continues ADA-PO achieves a performance ratio of at least r. If Φ(wi+1) ≥ M then a performance ratio of r is guaranteed, due to M si+1+1−wi+1 ≤ r, from constraint [β]. Suppose then Φi(wi+1) < M, then by constraints [M] and [u] we know that wi+1 < 1. When the next rate pi+1 > pi is revealed the same analysis can be applied. We thus obtain a non-decreasing sequence of reservation rates Φj (pj ) for j > i. For each rate, problem Oi is solved. Note that the feasibility of problem Oi with rate pi implies the feasibility of the problem Oi with the next rate as shown by the next analysis. Namely, if pi ≤ Φ(pi−1) then w = wi , Φi = Φi−1 is a solution, and if pi > Φ(pi−1), then w = Φ−1 i−1 (pi), Φi = Φi−1 is as well. Furthermore, both cases lead to a performance ratio of at least r in case the next rate equals 1 and is the last rate. We hence conclude, that either one of the reservation rates is greater or equal than M or ADA-PO successfully achieves a performance ratio of r for each rate (wi < 1 was a solution for each problem). We conclude then that ADA-PO is r-robust.

We will now prove that ADA-PO is c(r)-consistent. We must prove that for every error-free sequence the performance ratio is at most c(r). Let A′ be any Pareto-Optimal algorithm. When observing rates below pˆ, ADA-PO follows the threat-based policy, hence for every error-free sequence, its budget is at least the same as A′ when a rate equal to pˆ is exhibited. Then by solving the optimization problem, ADA-PO exchanges the most it can in order to remain r-robust, a larger amount would make the problem infeasible. In other words, there would not exist a function Φ satisfying the constraints, and the continuously increasing function from pˆ to M will lead to a performance ratio bigger than r. Hence, no other algorithm could achieve a better profit. We conclude that ADA-PO is c(r)-consistent.

We finally prove that ADA-PO dominates A′ . By the previous analysis, when observing the first rate above the prediction, ADA-PO has a budget at least the budget than A′ . As ADA-PO exchanges the most it can to remain r-robust, it will obtain a next utilization which is equal or smaller than A′ , hence achieving a better profit, because A′ exchanged the same or less at lower rates. If A′ has behaved the same as ADA-PO, then this process repeats for every following rate. We conclude then that ADA-PO dominates or performs equally to A′ .

Remark C.1. To conclude we offer an intuitive explanation of dominance. If the maximum rate of the sequence is below the prediction, then ADA-PO's profit will be smaller or equal than any other Pareto-Optimal algorithm. Its profit will be equal if the sequence is a continuously increasing one. Moreover, for the first rate equal or greater than the prediction, its profit will be greater or equal than any other Pareto-Optimal algorithm. By definition of dominance, while observing rates above the prediction, either the two profits will be equal, or ADA-PO's profit is larger, unless the Pareto-Optimal algorithm attained a smaller profit at an earlier rate.

#### D Profile-based contract scheduling

In this section, we discuss another application of our profile-based framework of Section 3. Specifically, we focus on another well-known optimization problem that has been studied under learning-augmented settings, namely contract scheduling. In its standard variant, the problem consists of finding an increasing sequence X = (xi)∞ i=0 which minimizes the *acceleration ratio*, formally defined as

$\texttt{acc}(X)=\sup_{T}\frac{T}{\ell(X,T)}$. (D.1)

where ℓ(X, T) denotes the *largest* contract completed by T in X, namely

$$\ell(X,T)=\operatorname*{max}_{j}\{x_{j}:\sum_{i=0}^{j}x_{i}\leq T\}.$$

Contract scheduling is a classic problem that has been studied under several settings. In its simplest variant stated above, the optimal acceleration ratio is equal to 4 [36], but many more complex settings have been studied in the literature; see [5] and references therein. In this section we are interested in the learning augmented setting introduced in [5] in which there is a *prediction* τ on the interruption time T. The prediction *error* is defined as η = |T − τ |. In this context, the consistency c(X) of schedule X is defined as

$$c(X)={\frac{\tau}{\ell(X,\tau)}},$$

whereas its robustness is defined as

$$r(X)=\operatorname*{sup}_{T\geq1}{\frac{T}{\ell(X,T)}},$$

i.e., the worst-case performance of X, assuming adversarial interruptions. Since the latter occur arbitrarily close to the completion time of any contract, we obtain an equivalent interpretation of the robustness as

$$r(X)=\operatorname*{sup}_{i\geq1}{\frac{\sum_{j=0}^{i}x_{j}}{x_{i-1}}}.$$

In [5] it was shown that the optimal consistency of a 4-robust schedule is equal to 2. However, as proven in [7], any such schedule suffers from brittleness. Namely, for any ϵ > 0, there exists a prediction τ and an actual interruption time T such that |T − τ | = ϵ, and any 4-robust and 2-consistent schedule satisfies ℓ(X, T) ≤ T +ϵ 4 .

In the remainder of this section we will show how to use our framework of profile-based performance so as to remedy this drawback. For definiteness, and to illustrate the application of the techniques, we consider the requirement that the performance of the schedule degrades linearly as a function of the prediction error. Namely, suppose that we require that f(X, T) := T /ℓ(X, T) be respect a profile Fϕ, where the latter is defined as a symmetric, bilinear function that is decreasing for T ≤ τ , and increasing for T ≥ τ , with slope ϕ, as illustrated in Figure 4. This profile is chosen by the schedule designer, and the angle ϕ captures the "smoothness" at which the schedule is required to degrade as a function of the prediction error.

![](_page_16_Figure_13.jpeg)

Figure 4: An illustration of the profile Fϕ.

More specifically, for a given prediction τ , and a profile Fϕ as above, we are interested in finding the best extension of Fϕ such that there exists a 4-robust schedule that respects the extension. We can thus define the analytical concept of *consistency according to* Fϕ as

$$c_{F_{\phi}}:=\operatorname*{sup}_{\tau}\operatorname*{inf}_{T}{\frac{T}{\ell(X,T)}}:\;X{\mathrm{~respects~}}F_{\phi}.$$

The following theorem states our main result.

Theorem D.1. Given a profile Fϕ and a prediction τ on an interruption time, we can compute a 4-robust schedule that respects Fϕ and has optimal consistency according to Fϕ.

*Proof.* We will assume that X if of the form (λ2 i )i∈Z. This is not a limiting assumption, as discussed in [7], and its purpose is to simplify the calculations. Since any 4-robust schedule is of the above form [7], it will suffice to compute a λ that satisfies the constraints of our problem, and the result will follow.

Recall that f(X, T) denotes the function T /ℓ(X, T). By definition, for every i ∈ N, f(X, T) is a linear, increasing function of T function in the interval Ik = [Tk, Tk+1] = [λ2 k , λ2 k+1], with smallest value equal to 2, and largest value equal to 4.

With the above observation in mind, for a given, fixed λ, let k be such that τ ∈ Ik+1, i.e., we have that ℓ(X, τ ) = λ2 k . Define α ∈ [1, 2] to be such that τ = αTk, and note that by construction, α is a function of λ. Moreover

$$f(X,\tau)=\frac{\tau}{\lambda2^{k}}=\frac{\alpha T_{k}}{\lambda2^{k}}=\frac{\alpha\lambda2^{k+1}}{\lambda2^{k}}=2\alpha,$$
 (D.2)

which implies that it suffices to compute α, then λ must be chosen so that λ = 2{log(2α)} , where {x} denotes the fractional part of x.

In order to minimize f, subject to X respecting the profile, λ must be chosen such that one of the two cases occur, which we analyze separately.

*Case 1.* The profile Fϕ has a unique intersection point with f at T = τ , and moreover F(Tk +ϵ) = 4, for infinitesimally small ϵ > 0. This situation is illustrated in Figure 5. For this case to arise, and for the schedule to be consistent with F, it must be that

$$\tan(\frac{\pi}{2}-\phi)\geq\frac{4-2}{T_{k+1}-T_{k}}=\frac{2}{T_{k}}=\frac{2\alpha}{\tau}.$$
 (D.3)

It must then be that f(X, τ ) + τ−Tk tan ϕ = 4, hence

$$4-\rho(1-\frac{1}{\alpha})=2\alpha,\;\mathrm{where}\;\rho=\frac{\tau}{\tan\phi}.$$

Solving the above equality for α minimizes f, by means of (D.2). We obtain that

$$\alpha=\frac{1}{4}(\sqrt{\rho^{2}+16}-\rho+4)\;\;\mathrm{and}\;\;f(X,\tau)=2\alpha,$$

subject to the condition (D.3).

![](_page_17_Figure_14.jpeg)

Figure 5: An illustration of Case 1.

*Case 2.* This case occurs if the condition in Case 1 does not apply. The profile Fϕ is such that F(Tk+ϵ) = F(Tk+1−ϵ)4r, for infinitesimally small ϵ > 0. This situation is illustrated in Figure 6. For this case to arise, and for the schedule to respect Fϕ it must be that τ = Tk+1+Tk 2 = 3 2 τ α , hence α = 3/2. In this case, we obtain that

$$f(X,\tau)=4-{\frac{T_{k+1}-\tau}{\tan\phi}}=4-\rho,{\mathrm{~where~}}\rho={\frac{\tau}{\tan\phi}}.$$

![](_page_18_Figure_0.jpeg)

We observe that in both cases in the analysis of Theorem D.1 we obtain that f ∈ (2, 4], as a function of τ and ϕ. This result makes intuitively sense, since X is 4-robust, and the smallest consistency is equal to 2 (when ϕ → 0).

#### E Further experimental analysis

To further quantify the performance difference between the two algorithms, PROFILE and PO, we performed additional experiments. Specifically, we used a list of the last 20,000 minute-exchange rates of BTC to USD, so as to create 20 different sequences, each with its own prediction, using the same method as in Fig 2c. For each sequence, we computed the average improvement over PO for rates in the interval of interest [0.9ˆp, 1.1ˆp]. Figure 7 depicts this average for each of the 20 sequences. We observe that for the sequences in which PROFILE outperforms PO (12 out of 20), the improvement ranges from roughly 15% to 30%, whereas PO outperforms PROFILE in 8 out of 20 sequences, by a factor that is at most 10%, roughly.

![](_page_18_Figure_4.jpeg)

Figure 7: Average ratio improvement of PROFILE over PO

